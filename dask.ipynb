{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3fb50e-51bb-4efb-8124-a5a02bb4615f",
   "metadata": {},
   "source": [
    "# Dask\n",
    "\n",
    "[Dask](https://dask.org/) is a library for parallel processing in Python, with a specific focus on analytic and scientific computing. Compared to Spark, it is more familiar to Python-oriented data scientists. In this notebook, we'll spin up an ad-hoc Dask cluster on top of CML sessions using the CML [Workers API](https://docs.cloudera.com/machine-learning/cloud/distributed-computing/topics/ml-workers-api.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b817ff-3683-40ac-addd-870d31e592a2",
   "metadata": {},
   "source": [
    "## Set up a Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140143f6-8bbc-49eb-8e3b-c89902eeb5e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install dask[complete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f1964-7860-4eaa-80a2-12802d555a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import cdsw\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ce70a-2c6b-40c5-9713-7faab233cde0",
   "metadata": {},
   "source": [
    "### Start Dask scheduler\n",
    "We need to make two directories required by Dask. Dask uses these directories to share network information between the scheduler and workers. From our, user, perspective, we can create them and forget them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e827240-2737-4434-b691-7347969057b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"_scheduler_\", exist_ok=True)\n",
    "os.makedirs(\"_worker_\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8693b0d2-924c-4d3f-87b5-be1a72ed78c0",
   "metadata": {},
   "source": [
    "We start a Dask scheduler as a CDSW worker process. We do this with cdsw.launch_workers, which spins up another session on our cluster and runs the command we provide â€” in this case the Dask scheduler. The scheduler is responsible for coordinating work between the Dask workers we will attach. Later we'll start a Dask client in this notebook. The client talks to the scheduler, and the scheduler talks to the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462ec45-4b1a-4119-b2e3-c73bb3a0781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_scheduler = cdsw.launch_workers(\n",
    "  n=1,\n",
    "  cpu=1,\n",
    "  memory=2,\n",
    "  code=f\"!dask-scheduler --host 0.0.0.0 --dashboard-address 127.0.0.1:8090 --scheduler-file /home/cdsw/_scheduler_/dask.log\"\n",
    ")\n",
    "\n",
    "# Wait for the scheduler to start.\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db17f95-e99f-437c-8b59-e0505f5a56a1",
   "metadata": {},
   "source": [
    "We need the IP address of the CML worker with the scheduler on it, so we can connect the Dask workers to it. The IP is not returned in the dask_scheduler object (it's unknown at the launch of the scheduler), so we scan through the worker list and find the IP of the worker with the scheduler id. This returns a list, but there should be only one entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a2e4e-7046-4aa8-9e00-98ce1d1b48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_workers = cdsw.list_workers()\n",
    "scheduler_id = dask_scheduler[0]['id']\n",
    "scheduler_ip = [worker['ip_address'] for worker in scheduler_workers\n",
    "                if worker['id'] == scheduler_id][0]\n",
    "\n",
    "scheduler_url = f\"tcp://{scheduler_ip}:8786\"\n",
    "\n",
    "scheduler_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dcb5c1-24a2-468a-92aa-95b201b5b78a",
   "metadata": {},
   "source": [
    "### Start Dask workers\n",
    "We're ready to grow our cluster. We start some more CML workers, each with one Dask worker process on it. We pass the scheduler URL we just found so that the scheduler can talk, and distribute work, to the workers.\n",
    "\n",
    "N_WORKERS determines the number of CML workers started (and thus the number of Dask workers running in those sessions). Increasing the number will start more workers. This will speed up the wall-clock time of the TPOT training process, by training more pipelines in parallel, but it uses more cluster resources. Exercise good judgement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220b142-79cc-452b-af43-85868096e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WORKERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5bcdc8-3a71-4e42-874d-4161367a423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_workers = cdsw.launch_workers(\n",
    "  n=N_WORKERS,\n",
    "  cpu=1,\n",
    "  memory=2,\n",
    "  code=f\"!dask-worker {scheduler_url} --local-directory /home/cdsw/_worker_\"\n",
    ")\n",
    "\n",
    "# Wait for the workers to start.\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a1d723-6d79-4b48-bb9f-89b5919d33f1",
   "metadata": {},
   "source": [
    "### Connect Dask client\n",
    "We have a Dask cluster running and distributed over CML sessions. Now we can start a local Dask client and connect it to our scheduler. This is the connection that lets us issue instructions to the Dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208bd6bd-e2ad-4f28-b3a9-79a4a244d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(scheduler_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8148b5-6380-4967-b9d1-9545fa8bbd9f",
   "metadata": {},
   "source": [
    "We can view some stats about the Dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652817e-2e9f-48e9-8b59-bf654f3b3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a8a63e-830a-4d2f-8ef3-674929cf45ba",
   "metadata": {},
   "source": [
    "The Dask scheduler hosts a dashboard so we can monitor the work it's doing. Here we construct the URL of dashboard, which is hosted on the scheduler worker. Clicking it should open the dashboard in a new browser window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d10d11-aef6-496e-816b-66a58817b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"//\".join(dask_scheduler[0][\"app_url\"].split(\"//\"))+ \"status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081918d-a7af-43ec-b5e5-8e49016f60b5",
   "metadata": {},
   "source": [
    "That's our Dask cluster set up, let's do something with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba279c3-06a3-4cfe-826b-0c8c7e3a3338",
   "metadata": {},
   "source": [
    "## Do some data science!\n",
    "\n",
    "Dask provides distributed equivalents to several popular and useful libraries in the Python data science ecosystem. Here we'll give a very brief demo to the loose equivalents of [NumPy](https://numpy.org/) (Dask Array), [Pandas](https://pandas.pydata.org/) (Dask DataFrames), and [scikit-learn](https://scikit-learn.org/stable/) (Dask ML)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2dffcb-11ca-4f91-b3ed-6328bb85dd0b",
   "metadata": {},
   "source": [
    "### Dask Arrays\n",
    "\n",
    "We can instantiate an array like this:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a66a6b4c-142b-4c90-bdd9-9bb9d6881778",
   "metadata": {},
   "source": [
    "TODO: make bigger, don't store in single chunk, and work out compatible chunk size for reshaping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d02a1-4617-4dd4-a513-0e9c84b8ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = da.random.random((1000, 1000), chunks=(1000, 1000))\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03396a6d-5bf6-435f-9912-748f6b757404",
   "metadata": {},
   "source": [
    "Then do numpy like manipulation on it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9810fa-8a3f-4574-aa62-1698efe6995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these manipulations do not carry any special meaning\n",
    "array = (\n",
    "    da.reshape(array, (2000, 500)) # reshape the array\n",
    "    .T                             # transpose it\n",
    "    [:10]                          # take only the first 10 elements of the outer axis\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f6cd56-2a88-48b3-9ad6-900f497c49a5",
   "metadata": {},
   "source": [
    "It even contains much of the NumPy linalg functionality, so we can do, for instance, a singular value decomposition of our transformed array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05ba97-41b0-4cd6-9753-b18b14a290ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vh = da.linalg.svd(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95749a2f-ed37-49dd-9d79-e950bf4e2730",
   "metadata": {},
   "source": [
    "The arrays we just computed with are distributed. To access their contents as a NumPy array, we must call `.compute()` explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925a53b-b831-454f-82bb-060eca85a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ea097-f8b1-44b0-b4c1-a41014f33f4d",
   "metadata": {},
   "source": [
    "### Dask DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596d421-b14b-420a-a477-e1af099fcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask provides a handy dataset for demo-ing itself\n",
    "df = dask.datasets.timeseries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e99028-fed9-4869-9388-a23322702b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b8d60-284b-4975-a3d9-491afe2361a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a22a1-64b0-46a9-ad04-79deb40ec794",
   "metadata": {},
   "outputs": [],
   "source": [
    "names.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52000084-2b53-442a-979e-f09860652939",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    [(df.name == 'Oliver')]\n",
    "    [['x', 'y']]\n",
    "    .cumsum()\n",
    "    .compute()\n",
    "    .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189184f-c048-43fb-b5d4-020b33816aa2",
   "metadata": {},
   "source": [
    "### Dask ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d900b-4df6-4b5c-979f-038e77f6fc3f",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce896d3-2a7f-4f71-9029-4929ef20340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdsw.stop_workers(*[worker[\"id\"] for worker in dask_workers+dask_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022a7ed-ccdd-4ec1-92b6-cd2d143fec30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
