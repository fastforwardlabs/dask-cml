{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3fb50e-51bb-4efb-8124-a5a02bb4615f",
   "metadata": {},
   "source": [
    "# Dask\n",
    "\n",
    "[Dask](https://dask.org/) is a library for parallel processing in Python, with a specific focus on analytic and scientific computing. Compared to Spark, it is more familiar to Python-oriented data scientists. In this notebook, we'll spin up an ad-hoc Dask cluster on top of CML sessions using the CML [Workers API](https://docs.cloudera.com/machine-learning/cloud/distributed-computing/topics/ml-workers-api.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b817ff-3683-40ac-addd-870d31e592a2",
   "metadata": {},
   "source": [
    "## Set up a Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140143f6-8bbc-49eb-8e3b-c89902eeb5e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[complete] in ./.local/lib/python3.7/site-packages (2021.9.1)\n",
      "Requirement already satisfied: dask-ml in ./.local/lib/python3.7/site-packages (2021.10.17)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/site-packages (from dask-ml) (1.19.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in ./.local/lib/python3.7/site-packages (from dask-ml) (1.0)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.7/site-packages (from dask-ml) (1.7.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from dask-ml) (20.9)\n",
      "Requirement already satisfied: dask-glm>=0.2.0 in ./.local/lib/python3.7/site-packages (from dask-ml) (0.2.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in ./.local/lib/python3.7/site-packages (from dask-ml) (1.3.3)\n",
      "Requirement already satisfied: multipledispatch>=0.4.9 in ./.local/lib/python3.7/site-packages (from dask-ml) (0.6.0)\n",
      "Requirement already satisfied: distributed>=2.4.0 in ./.local/lib/python3.7/site-packages (from dask-ml) (2021.9.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.local/lib/python3.7/site-packages (from dask-ml) (0.54.1)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in ./.local/lib/python3.7/site-packages (from dask-glm>=0.2.0->dask-ml) (2.0.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in ./.local/lib/python3.7/site-packages (from dask[complete]) (2021.10.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in ./.local/lib/python3.7/site-packages (from dask[complete]) (1.2.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in ./.local/lib/python3.7/site-packages (from dask[complete]) (0.11.1)\n",
      "Requirement already satisfied: pyyaml in ./.local/lib/python3.7/site-packages (from dask[complete]) (5.4.1)\n",
      "Requirement already satisfied: psutil>=5.0 in ./.local/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (5.8.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in ./.local/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (2.4.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in ./.local/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (1.0.2)\n",
      "Requirement already satisfied: zict>=0.1.3 in ./.local/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (2.0.0)\n",
      "Requirement already satisfied: click>=6.6 in ./.local/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (8.0.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (47.1.0)\n",
      "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (6.1)\n",
      "Requirement already satisfied: tblib>=1.6.0 in ./.local/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (1.7.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (2.11.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from click>=6.6->distributed>=2.4.0->dask-ml) (3.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from multipledispatch>=0.4.9->dask-ml) (1.15.0)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in ./.local/lib/python3.7/site-packages (from numba>=0.51.0->dask-ml) (0.37.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->dask-ml) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas>=0.24.2->dask-ml) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas>=0.24.2->dask-ml) (2021.1)\n",
      "Requirement already satisfied: locket in ./.local/lib/python3.7/site-packages (from partd>=0.3.10->dask[complete]) (0.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.7/site-packages (from scikit-learn>=1.0.0->dask-ml) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.7/site-packages (from scikit-learn>=1.0.0->dask-ml) (1.1.0)\n",
      "Requirement already satisfied: heapdict in ./.local/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=2.4.0->dask-ml) (1.0.1)\n",
      "Requirement already satisfied: bokeh!=2.0.0,>=1.0.0 in ./.local/lib/python3.7/site-packages (from dask[complete]) (2.4.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/site-packages (from bokeh!=2.0.0,>=1.0.0->dask[complete]) (8.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in ./.local/lib/python3.7/site-packages (from bokeh!=2.0.0,>=1.0.0->dask[complete]) (3.10.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/site-packages (from jinja2->distributed>=2.4.0->dask-ml) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->click>=6.6->distributed>=2.4.0->dask-ml) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install dask[complete] dask-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421f1964-7860-4eaa-80a2-12802d555a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import cdsw\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import dask_ml as dm\n",
    "import dask_ml.datasets\n",
    "import dask_ml.linear_model\n",
    "\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ce70a-2c6b-40c5-9713-7faab233cde0",
   "metadata": {},
   "source": [
    "### Start Dask scheduler\n",
    "We need to make two directories required by Dask. Dask uses these directories to share network information between the scheduler and workers. From our, user, perspective, we can create them and forget them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e827240-2737-4434-b691-7347969057b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"_scheduler_\", exist_ok=True)\n",
    "os.makedirs(\"_worker_\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8693b0d2-924c-4d3f-87b5-be1a72ed78c0",
   "metadata": {},
   "source": [
    "We start a Dask scheduler as a CDSW worker process. We do this with cdsw.launch_workers, which spins up another session on our cluster and runs the command we provide â€” in this case the Dask scheduler. The scheduler is responsible for coordinating work between the Dask workers we will attach. Later we'll start a Dask client in this notebook. The client talks to the scheduler, and the scheduler talks to the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8462ec45-4b1a-4119-b2e3-c73bb3a0781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_scheduler = cdsw.launch_workers(\n",
    "  n=1,\n",
    "  cpu=1,\n",
    "  memory=2,\n",
    "  code=f\"!dask-scheduler --host 0.0.0.0 --dashboard-address 127.0.0.1:8090 --scheduler-file /home/cdsw/_scheduler_/dask.log\"\n",
    ")\n",
    "\n",
    "# Wait for the scheduler to start.\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db17f95-e99f-437c-8b59-e0505f5a56a1",
   "metadata": {},
   "source": [
    "We need the IP address of the CML worker with the scheduler on it, so we can connect the Dask workers to it. The IP is not returned in the dask_scheduler object (it's unknown at the launch of the scheduler), so we scan through the worker list and find the IP of the worker with the scheduler id. This returns a list, but there should be only one entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f3a2e4e-7046-4aa8-9e00-98ce1d1b48f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tcp://100.66.192.4:8786'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler_workers = cdsw.list_workers()\n",
    "scheduler_id = dask_scheduler[0]['id']\n",
    "scheduler_ip = [worker['ip_address'] for worker in scheduler_workers\n",
    "                if worker['id'] == scheduler_id][0]\n",
    "\n",
    "scheduler_url = f\"tcp://{scheduler_ip}:8786\"\n",
    "\n",
    "scheduler_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dcb5c1-24a2-468a-92aa-95b201b5b78a",
   "metadata": {},
   "source": [
    "### Start Dask workers\n",
    "We're ready to grow our cluster. We start some more CML workers, each with one Dask worker process on it. We pass the scheduler URL we just found so that the scheduler can talk, and distribute work, to the workers.\n",
    "\n",
    "N_WORKERS determines the number of CML workers started (and thus the number of Dask workers running in those sessions). Increasing the number will start more workers. This will speed up the wall-clock time of the TPOT training process, by training more pipelines in parallel, but it uses more cluster resources. Exercise good judgement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2220b142-79cc-452b-af43-85868096e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WORKERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5bcdc8-3a71-4e42-874d-4161367a423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_workers = cdsw.launch_workers(\n",
    "  n=N_WORKERS,\n",
    "  cpu=1,\n",
    "  memory=2,\n",
    "  code=f\"!dask-worker {scheduler_url} --local-directory /home/cdsw/_worker_\"\n",
    ")\n",
    "\n",
    "# Wait for the workers to start.\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a1d723-6d79-4b48-bb9f-89b5919d33f1",
   "metadata": {},
   "source": [
    "### Connect Dask client\n",
    "We have a Dask cluster running and distributed over CML sessions. Now we can start a local Dask client and connect it to our scheduler. This is the connection that lets us issue instructions to the Dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "208bd6bd-e2ad-4f28-b3a9-79a4a244d7b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Timed out trying to connect to tcp://100.66.192.4:8786 after 30 s",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/distributed/comm/core.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, timeout, deserialize, handshake_overrides, **connection_args)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0mconnector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconnection_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_cap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/asyncio/tasks.py\u001b[0m in \u001b[0;36mwait_for\u001b[0;34m(fut, timeout, loop)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;32mawait\u001b[0m \u001b[0m_cancel_and_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d80f28e516be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, address, loop, timeout, set_as_default, scheduler_file, security, asynchronous, name, heartbeat_interval, serializers, deserializers, extensions, direct_to_workers, connection_limit, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         \u001b[0mClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__await__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_timeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                         \u001b[0mexc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m             \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_ensure_connected\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m             comm = await connect(\n\u001b[0;32m-> 1091\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m             )\n\u001b[1;32m   1093\u001b[0m             \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Client->Scheduler\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/distributed/comm/core.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, timeout, deserialize, handshake_overrides, **connection_args)\u001b[0m\n\u001b[1;32m    307\u001b[0m         raise OSError(\n\u001b[1;32m    308\u001b[0m             \u001b[0;34mf\"Timed out trying to connect to {addr} after {timeout} s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         ) from active_exception\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     local_info = {\n",
      "\u001b[0;31mOSError\u001b[0m: Timed out trying to connect to tcp://100.66.192.4:8786 after 30 s"
     ]
    }
   ],
   "source": [
    "client = Client(scheduler_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8148b5-6380-4967-b9d1-9545fa8bbd9f",
   "metadata": {},
   "source": [
    "We can view some stats about the Dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652817e-2e9f-48e9-8b59-bf654f3b3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a8a63e-830a-4d2f-8ef3-674929cf45ba",
   "metadata": {},
   "source": [
    "The Dask scheduler hosts a dashboard so we can monitor the work it's doing. Here we construct the URL of dashboard, which is hosted on the scheduler worker. Clicking it should open the dashboard in a new browser window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d10d11-aef6-496e-816b-66a58817b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"//\".join(dask_scheduler[0][\"app_url\"].split(\"//\"))+ \"status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081918d-a7af-43ec-b5e5-8e49016f60b5",
   "metadata": {},
   "source": [
    "That's our Dask cluster set up, let's do something with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba279c3-06a3-4cfe-826b-0c8c7e3a3338",
   "metadata": {},
   "source": [
    "## Do some data science!\n",
    "\n",
    "Dask provides distributed equivalents to several popular and useful libraries in the Python data science ecosystem. Here we'll give a very brief demo to the loose equivalents of [NumPy](https://numpy.org/) (Dask Array), [Pandas](https://pandas.pydata.org/) (Dask DataFrames), and [scikit-learn](https://scikit-learn.org/stable/) (Dask ML)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2dffcb-11ca-4f91-b3ed-6328bb85dd0b",
   "metadata": {},
   "source": [
    "### Dask Arrays\n",
    "\n",
    "We can instantiate an array like this:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a66a6b4c-142b-4c90-bdd9-9bb9d6881778",
   "metadata": {},
   "source": [
    "TODO: make bigger, don't store in single chunk, and work out compatible chunk size for reshaping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d02a1-4617-4dd4-a513-0e9c84b8ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = da.random.random((1000, 1000), chunks=(1000, 1000))\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03396a6d-5bf6-435f-9912-748f6b757404",
   "metadata": {},
   "source": [
    "Then do NumPy-like manipulation on it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9810fa-8a3f-4574-aa62-1698efe6995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these manipulations do not carry any special meaning\n",
    "array = (\n",
    "    da.reshape(array, (2000, 500)) # reshape the array\n",
    "    .T                             # transpose it\n",
    "    [:10]                          # take only the first 10 elements of the outer axis\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f6cd56-2a88-48b3-9ad6-900f497c49a5",
   "metadata": {},
   "source": [
    "It even contains much of the NumPy linalg functionality, so we can do, for instance, a singular value decomposition of our transformed array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05ba97-41b0-4cd6-9753-b18b14a290ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vh = da.linalg.svd(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95749a2f-ed37-49dd-9d79-e950bf4e2730",
   "metadata": {},
   "source": [
    "The arrays we just computed with are distributed. To access their contents as a NumPy array, we must call `.compute()` explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925a53b-b831-454f-82bb-060eca85a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ea097-f8b1-44b0-b4c1-a41014f33f4d",
   "metadata": {},
   "source": [
    "### Dask DataFrames\n",
    "\n",
    "Dask DataFrames are extremely similar to Pandas DataFrames. In fact, Dask is really just co-ordinating Pandas objects under the hood. As such, we have access to most of the Pandas API, with the caveat that operations will be faster or slower depending on their degree of parallelizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596d421-b14b-420a-a477-e1af099fcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask provides a handy dataset for demo-ing itself\n",
    "df = dask.datasets.timeseries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc5b62-533b-47a9-912c-0ac66d2caa7d",
   "metadata": {},
   "source": [
    "We can take a peak at the head of the DataFrame, which will return the head of the first Pandas DataFrame in the Dask structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e99028-fed9-4869-9388-a23322702b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d173db3-7f38-4aaa-98ff-5748dc9838b5",
   "metadata": {},
   "source": [
    "We can do standard DataFrame operations, like finding the unique values of a column. This is an operation on distributed data, so we must call `.compute()` to collect the result. When we call `.head()`, the result is collected for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b8d60-284b-4975-a3d9-491afe2361a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df['name'].unique().values\n",
    "names.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30cbceb-4cb8-4222-9706-426418c1fd31",
   "metadata": {},
   "source": [
    "We can chain operations as usual. Once we've called `.compute()`, we're left with a Pandas DataFrame, and can call regular Pandas methods (like `.plot()`) on it.\n",
    "\n",
    "(There's no special meaning to the operations below. We're just taking the column-wise cumulative sum of some random numbers for a filtered set of data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52000084-2b53-442a-979e-f09860652939",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    [(df.name == 'Oliver')]\n",
    "    [['x', 'y']]\n",
    "    .cumsum()\n",
    "    .compute()\n",
    "    .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189184f-c048-43fb-b5d4-020b33816aa2",
   "metadata": {},
   "source": [
    "### Dask ML\n",
    "\n",
    "Dask ML supports several machine learning frameworks, mostly through scikit-learn integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c6a7b2-13b2-4823-a2b0-936dd9f41d2a",
   "metadata": {},
   "source": [
    "First, generate a fake classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddcca18-440c-4cc1-a048-801ca1bcb37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dm.datasets.make_classification(\n",
    "    n_samples=100_000,\n",
    "    chunks=10_000,\n",
    "    random_state=123)\n",
    "X = X.persist()\n",
    "y = y.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a567d-ed1c-4acf-a374-819632b271bc",
   "metadata": {},
   "source": [
    "And define a logistic regression model with L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a915c2-4205-4baf-a7e4-83893ca9fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = dm.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b89356-7536-4e77-8e78-282451b87844",
   "metadata": {},
   "source": [
    "We can fit that on the distributed Dask dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1adec-8173-4d5e-a474-c7092a0f6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e3a78-1784-40b4-95c2-dfb30c9b3cac",
   "metadata": {},
   "source": [
    "And report our training loss. The trained algorithm is still a Dask object, so we must call `.compute()` to retrieve the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18830a23-bf5f-47f7-922c-95468220c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X, y).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d900b-4df6-4b5c-979f-038e77f6fc3f",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce896d3-2a7f-4f71-9029-4929ef20340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdsw.stop_workers(*[worker[\"id\"] for worker in dask_workers+dask_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022a7ed-ccdd-4ec1-92b6-cd2d143fec30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
